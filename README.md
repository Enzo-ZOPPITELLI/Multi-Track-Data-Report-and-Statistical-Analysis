# Multi-Track-Data-Report-and-Statistical-Analysis
## Python script that loads all Excel sheets, cleans and standardizes student data, merges tracks into a single dataset, and generates statistical reports (scores, attendance, pass rates) across tracks, cohorts, and income groups. Fully automated and reusable for future datasets.
### How my project work ?
I had a document "student_grades_2027-2028.xlsx". First, I uploaded this Excel file into my Jupyter Notebook, then analyzed and cleaned the data in order to reorganize it and merge everything into a single CSV file according to the given instructions. Second, I computed all the statistics related to the dataset (attendance percentage, average scores for each subject—Mathematics, English, Science, and History—by track (BM, Data, Finance), as well as pass rates for each subject). This allowed me to generate a second CSV file containing all the statistics, giving a global overview of the data.Third, I created several visualizations using histograms and scatter plots (distribution of History scores, average Mathematics scores by track shown as a bar chart, correlation between attendance and project score for each track, etc.). Fourth, I analyzed pass rates by cohort and compared academic performance between income-supported students and others. Finally, I compiled all these results into a single Excel file containing multiple sheets : 'summary_report.xlsx.
### What documents I upload on Github
I upload my python script 'Projet python.ipynb', my final excel file wicht summarize everything ('summary_report.xlsx'). There are also others summary I made during the python script ('track_summary.csv', 'merged_clean_part1.csv', 'cohort_summary.csv', 'attendance_project_correlation.csv') and figures ('bar_math_mean_by_track.png', 'boxplot_histoy_by_track.png', 'hist_history_BM.png', 'hist_history_Data.png', 'hist_history_Finance.png', 'scatter_attendance_project_BM.png', 'scatter_attendance_project_Date.png' and 'scatter_attendance_project_Finance.png'

### How I did it
I used AI to build the structure of my code, then relied on my knowledge of various Python libraries to refine everything and ensure the code addressed the problem while removing any unnecessary elements. In this way, I was able to acquire the basics of Python to sort, reorganize, and modify a database while analyzing it. I can now understand such Python code — the different ways it works and the logical structure behind it. I am certain this will be useful for achieving my professional goal: becoming a sales representative in a major tech company.
